{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11151587,"sourceType":"datasetVersion","datasetId":6829806}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip -q install transformers huggingface_hub langdetect pycountry","metadata":{"_uuid":"5a9de2b7-d1cf-437d-9785-8059db2107bb","_cell_guid":"72d8a046-c400-4fa8-8aab-b0e00143d37f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-28T04:14:14.235497Z","iopub.execute_input":"2025-03-28T04:14:14.235951Z","iopub.status.idle":"2025-03-28T04:14:25.735560Z","shell.execute_reply.started":"2025-03-28T04:14:14.235909Z","shell.execute_reply":"2025-03-28T04:14:25.734284Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport torch\nimport scipy.stats as stats\nimport re\nimport nltk\nfrom nltk.corpus import words\nfrom collections import Counter\nimport math\nimport unicodedata\nimport time\nfrom tqdm import tqdm\nimport pickle\nfrom langdetect import detect\nimport warnings\nimport pycountry\nfrom scipy import stats\nfrom collections import defaultdict\nimport itertools\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T04:14:25.736886Z","iopub.execute_input":"2025-03-28T04:14:25.737308Z","iopub.status.idle":"2025-03-28T04:14:33.232440Z","shell.execute_reply.started":"2025-03-28T04:14:25.737266Z","shell.execute_reply":"2025-03-28T04:14:33.231229Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Load sentiment data with sentiment features calculated\nX_train = pd.read_pickle('/kaggle/input/reviews-analyzer-dataset/sentiment_data/X_train.pkl')\ny_train = pd.read_pickle('/kaggle/input/reviews-analyzer-dataset/sentiment_data/y_train.pkl')\nX_test = pd.read_pickle('/kaggle/input/reviews-analyzer-dataset/sentiment_data/X_test.pkl')\ny_test = pd.read_pickle('/kaggle/input/reviews-analyzer-dataset/sentiment_data/y_test.pkl')\n\n# Recombine becuase we forgot to not split before\nsample_size = 100\nfile_path = '/kaggle/working/embeddings.npy'\nif os.path.exists(file_path):\n    os.remove(file_path)\n    print(f\"File '{file_path}' has been deleted.\")\nelse:\n    print(f\"File '{file_path}' does not exist.\")\n\ntrain_df = pd.concat([X_train, y_train], axis=1).sample(n=sample_size)\ntest_df = pd.concat([X_test, y_test], axis=1).sample(n=sample_size)\n\nprint(train_df.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T04:14:33.233507Z","iopub.execute_input":"2025-03-28T04:14:33.234457Z","iopub.status.idle":"2025-03-28T04:14:37.145610Z","shell.execute_reply.started":"2025-03-28T04:14:33.234403Z","shell.execute_reply":"2025-03-28T04:14:37.144260Z"}},"outputs":[{"name":"stdout","text":"File '/kaggle/working/embeddings.npy' does not exist.\nIndex(['pos_word_count', 'neg_word_count', 'negated_pos_count',\n       'negated_neg_count', 'pos_ngram_count', 'neg_ngram_count',\n       'polarity_score', 'exclamation_count', 'uppercase_ratio', 'review',\n       'sentiment'],\n      dtype='object')\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# FEATURE - Calculate entropy\ndef calculate_entropy(text):\n    \"\"\"Calculate Shannon entropy of the text to detect randomness.\"\"\"\n    if not text:\n        return 0\n    if not isinstance(text, str) or pd.isna(text):\n        return 0  # Return 0 for NaN or non-string values\n    text = str(text).lower()\n    length = len(text)\n    if length == 0:  # Handle empty strings\n        return 0\n    char_counts = Counter(text)\n    entropy = -sum((count/length) * math.log2(count/length) for count in char_counts.values())\n    return entropy\n\ndef create_entropy_feature(df, review_col='review'):\n    tqdm.pandas(desc='Calculating entropies: ')\n    df['entropy'] = df['review'].progress_apply(calculate_entropy)\n    return df\n\n# Suppress langdetect warnings for cleaner output\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\ndef detect_language(text):\n\n    if not isinstance(text, str) or pd.isna(text) or len(text.strip()) < 3:\n        return 'unknown'  # For NaN, empty, or very short text\n    try:\n        return detect(text)\n    except:\n        return 'unknown'  # Fallback for any detection errors\n\n# Returns 0 if we can't find the langauge, 1 if we can\ndef cannot_detect_language(text):\n    if text == 'unknown':\n        return 1\n    else:\n        return 0\n\ndef create_can_detect_feature(df, review_col='review'):\n    tqdm.pandas(desc=\"Detecting Language...\")\n    df['language'] = df[review_col].progress_apply(detect_language)\n    df['cannot_detect_language'] = df['language'].progress_apply(cannot_detect_language)\n    return df\n\n# 3x FEATURES - Total characters in review, word count of review, avg word length\ndef word_count(text):\n    words = re.split(f'\\s+', text.strip())\n    word_count = len(words)\n    return word_count\n\ndef char_count(text):\n    return len(text)\n\ndef create_word_and_char_counts_feature(df, review_col='review'):\n    tqdm.pandas(desc='Getting word/char counts...')\n    df['word_count'] = df[review_col].progress_apply(word_count)\n    df['n_chars'] = df[review_col].progress_apply(char_count)\n    return df\n\ndef get_avg_word_length(text):\n    # avg word length\n    words = re.split(f'\\s+', text.strip())\n    word_count = len(words)\n    avg_word_length = sum(len(word) for word in words if word) / max(1, word_count) if words else 0\n    return avg_word_length\n\ndef create_avg_word_length_feature(df, review_col='review'):\n    tqdm.pandas(desc='Getting avg word length feature...')\n    df['avg_word_length'] = df[review_col].progress_apply(get_avg_word_length)\n    return df\n\n# FEATURE - Amount of Reptition\ndef get_max_repeated(text):\n    max_repeats = max([sum(1 for _ in g) for _, g in itertools.groupby(text)] or [0])\n    return max_repeats\ndef create_repetition_feature(df, review_col='review'):\n    tqdm.pandas(desc='Creating repetition feature...')\n    df['max_repeated'] = df[review_col].progress_apply(get_max_repeated)\n    return df\n\ndef get_punct_ratio(text):\n    char_length = len(text)\n    punct_count = sum(1 for c in text if c in '.,!?')\n    punct_ratio = punct_count / max(1, char_length)\n    return punct_ratio\n    \ndef create_punct_ratio_feature(df, review_col='review'):\n    tqdm.pandas(desc='Creating punctuation ratio feature...')\n    df['punct_ratio'] = df[review_col].progress_apply(get_punct_ratio)\n    return df\n\n# FEATURE - Contains common n-grams\n# Step 1 - Build n-gram reference from sample of real reviews\ndef build_ngram_reference(texts, n=2, top_k=1000, sample_size=10000):\n\n    # Sample texts to avoid over-processing (e.g., 1.19M reviews)\n    if len(texts) > sample_size:\n        texts = np.random.choice(texts, sample_size, replace=False)\n    \n    # Generate n-grams\n    ngrams = Counter()\n    for text in tqdm(texts, desc=\"Building n-gram reference...\"):\n        text = str(text).lower()\n        for i in range(len(text) - n + 1):\n            ngram = text[i:i+n]\n            if not ngram.isspace():\n                ngrams[ngram] += 1\n    \n    # Return top k most common n-grams\n    return set([ngram for ngram, _ in ngrams.most_common(top_k)])\n\n# FEATURE - ngram coherence, fraction of ngrams that appear in list of common ngrams\ndef get_ngram_coherence(text, n=2):\n    text_lower = text.lower()\n    total_ngrams = max(1, len(text_lower) - n + 1)\n    valid_ngrams = sum(1 for i in range(total_ngrams) if text_lower[i:i+n] in ngram_ref)\n    ngram_coherence = valid_ngrams / total_ngrams\n    return ngram_coherence\n\ndef create_ngram_coherence_feature(df, ngram_ref, review_col='review'):\n    tqdm.pandas(desc='Calcualting ngram coherenece...')\n    df['ngram_coherence'] = df[review_col].progress_apply(get_ngram_coherence)\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T04:14:37.146994Z","iopub.execute_input":"2025-03-28T04:14:37.147524Z","iopub.status.idle":"2025-03-28T04:14:37.168245Z","shell.execute_reply.started":"2025-03-28T04:14:37.147474Z","shell.execute_reply":"2025-03-28T04:14:37.166480Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from transformers import XLMRobertaTokenizer, XLMRobertaModel\nimport torch\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Load pre-trained XLM-R model and tokenizer\ntokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\nmodel = XLMRobertaModel.from_pretrained('xlm-roberta-base')\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\nmodel.eval()\n\n# Function to get embeddings in batches\ndef get_embeddings(texts, batch_size=32):\n    embeddings = []\n    for i in tqdm(range(0, len(texts), batch_size), desc=\"Generating embeddings\"):\n        batch_texts = texts[i:i + batch_size]\n        inputs = tokenizer(batch_texts, return_tensors='pt', padding=True, truncation=True, max_length=128)\n        inputs = {k: v.to(device) for k, v in inputs.items()}\n        with torch.no_grad():\n            outputs = model(**inputs)\n        # Use [CLS] token embedding (first token)\n        batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n        embeddings.append(batch_embeddings)\n    return np.vstack(embeddings)\n    \n# Compute centroid from substantive reviews\ndef compute_centroid(df, review_col='review', label_col='is_gibberish', sample_size=10000):\n    # Use real reviews (training data only)\n    real_texts = df[df[label_col] == 0][review_col].dropna().tolist()\n    if len(real_texts) > sample_size:\n        real_texts = np.random.choice(real_texts, sample_size, replace=False).tolist()\n    embeddings = get_embeddings(real_texts)\n    return np.mean(embeddings, axis=0)\n\n# Add embedding-based features\ndef add_embedding_features(df, centroid, review_col='review', embed_path=None):\n    if embed_path and os.path.exists(embed_path):\n        print(f\"Loading embeddings from {embed_path}\")\n        embeddings = np.load(embed_path)\n    else:\n        texts = df[review_col].fillna('').tolist()\n        embeddings = get_embeddings(texts)\n        if embed_path:\n            np.save(embed_path, embeddings)\n            print(f\"Saved embeddings to {embed_path}\")\n    \n    # Cosine similarity to centroid\n    cosine_sim = cosine_similarity(embeddings, centroid.reshape(1, -1)).flatten()\n    \n    # Anomaly score (Euclidean distance)\n    anomaly_score = np.linalg.norm(embeddings - centroid, axis=1)\n    \n    df['cosine_to_centroid'] = cosine_sim\n    df['anomaly_score'] = anomaly_score\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T04:14:37.171444Z","iopub.execute_input":"2025-03-28T04:14:37.171911Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_feature_df(df, review_col='review', ngram_ref=None, centroid=None):\n    df = create_entropy_feature(df, review_col='review')\n    df = create_can_detect_feature(df, review_col='review')\n    #df = create_alphabet_tag_feature(df, review_col='review')\n    df = create_word_and_char_counts_feature(df, review_col='review')\n    df = create_avg_word_length_feature(df, review_col='review')\n    df = create_repetition_feature(df, review_col='review')\n    df = create_punct_ratio_feature(df, review_col='review')\n    df = create_ngram_coherence_feature(df, ngram_ref, review_col='review')\n    df = add_embedding_features(df, centroid)\n    #train_embed_path = 'train_embeddings.npy'\n    #test_embed_path = 'test_embeddings.npy'\n    return df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load precomputed centroid and ngram_ref from Amazon full training set\nwith open('/kaggle/input/reviews-analyzer-dataset/coursera_gibberish/ngram_ref.pkl', 'rb') as f:\n    ngram_ref = pickle.load(f)\nwith open('/kaggle/input/reviews-analyzer-dataset/coursera_gibberish/centroid.pkl', 'rb') as f:\n    centroid = pickle.load(f)\n    \n# Step 3: Create feature DataFrames\ntrain_features = create_feature_df(train_df, ngram_ref=ngram_ref, centroid=centroid)\ntest_features = create_feature_df(test_df, ngram_ref=ngram_ref, centroid=centroid)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_features.columns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Choose the relevant columns\nmodel_features = ['cannot_detect_language', 'entropy', 'word_count', 'avg_word_length',\n                  'ngram_coherence', 'anomaly_score', 'punct_ratio', 'max_repeated']\nfeed_into_model_df = train_features.reindex(columns=model_features)\n\n# Run the model on coursera stuff\nmodel_path = '/kaggle/input/reviews-analyzer-dataset/gibberish_random_forest_model.pkl'\nwith open(model_path, 'rb') as f:\n    model = pickle.load(f)\nfeed_into_model_df['is_gibberish'] = model.predict(feed_into_model_df)\nfeed_into_model_df['review'] = train_features['review']\nfeed_into_model_df['polarity_score'] = train_features['polarity_score']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feed_into_model_df.is_gibberish.value_counts()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Add a simple rule for short reviews\ndef adjust_predictions(X, predictions, threshold=5, polarity_min=0.3):\n    adjusted_preds = predictions.copy()\n    for i in range(len(X)):\n        total_words = X.iloc[i]['pos_word_count'] + X.iloc[i]['neg_word_count']\n        polarity = X.iloc[i]['polarity_score']\n        if total_words < threshold and polarity > polarity_min:\n            adjusted_preds[i] = 'non-gibberish'  # Override for short, positive reviews\n    return adjusted_preds","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n# Assuming your dataframe is called 'df'\ndef explore_gibberish_reviews(df):\n    \n    # 1. Basic statistics\n    print(\"Basic Statistics:\")\n    print(df.describe())\n    \n    # 2. Distribution of numerical features by sentiment\n    numerical_cols = ['cannot_detect_language', 'entropy', 'word_count', 'avg_word_length',\n                  'ngram_coherence', 'anomaly_score', 'punct_ratio', 'max_repeated']\n    \n    fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n    axes = axes.ravel()\n    \n    for idx, col in enumerate(numerical_cols):\n        sns.boxplot(data=df, x='is_gibberish', y=col, ax=axes[idx])\n        #sns.histplot(data=df, x=)\n        axes[idx].set_title(f'Distribution of {col}')\n        axes[idx].tick_params(axis='x', rotation=45)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # 3. Correlation heatmap\n    plt.figure(figsize=(10, 8))\n    correlation_matrix = df[numerical_cols].corr()\n    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n    plt.title('Correlation Between Features')\n    plt.show()\n   \n    # 6. Word count analysis\n    df['total_word_count'] = df['pos_word_count'] + df['neg_word_count']\n    plt.figure(figsize=(8, 6))\n    sns.scatterplot(data=df, x='total_word_count', y='polarity_score', \n                   hue='is_gibberish', alpha=0.6)\n    plt.title('Word Count vs Polarity Score by Gibberish')\n    plt.show()\n    \n\nexplore_gibberish_reviews(feed_into_model_df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\n# 4. Analyze false positives (non-gibberish labeled as gibberish)\n    # Assuming 'sentiment' column has 'gibberish' and 'non-gibberish' labels\n    false_positives = df[(df['review'].str.contains('great', case=False))]\n    \n    print(f\"\\nNumber of false positives with 'great': {len(false_positives)}\")\n    print(\"\\nSample of false positives:\")\n    print(false_positives[['cannot_detect_language', 'entropy', 'word_count', \n                           'avg_word_length','ngram_coherence', 'anomaly_score', \n                           'punct_ratio', 'max_repeated', 'review', \n                           'cannot_detect_language']].head())\n    \n    # 5. Feature distributions for false positives vs all data\n    plt.figure(figsize=(12, 4))\n    \n    plt.subplot(1, 3, 1)\n    sns.kdeplot(data=df, x='polarity_score', label='All')\n    sns.kdeplot(data=false_positives, x='polarity_score', label='False Positives')\n    plt.title('Polarity Score Distribution')\n    plt.legend()\n    \n    plt.subplot(1, 3, 2)\n    sns.kdeplot(data=df, x='uppercase_ratio', label='All')\n    sns.kdeplot(data=false_positives, x='uppercase_ratio', label='False Positives')\n    plt.title('Uppercase Ratio Distribution')\n    plt.legend()\n    \n    plt.subplot(1, 3, 3)\n    sns.kdeplot(data=df, x='exclamation_count', label='All')\n    sns.kdeplot(data=false_positives, x='exclamation_count', label='False Positives')\n    plt.title('Exclamation Count Distribution')\n    plt.legend()\n    \n    plt.tight_layout()\n    plt.show()\n\n     # 7. Print some example reviews\n    print(\"\\nExample reviews labeled as gibberish with 'GREAT AND EXEMPLARY':\")\n    exemplar_cases = df[df['review'].str.contains('great and exemplary', \n                        case=False) & (df['sentiment'] == 'gibberish')]\n    if not exemplar_cases.empty:\n        print(exemplar_cases[['review'] + numerical_cols].head())\n    else:\n        print(\"No exact matches found for 'GREAT AND EXEMPLARY'\")\n    '''","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}